{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efebf737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook 3 - basic processing of the data, joining files \n",
    "# together and removing unwanted sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8329bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fde13c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# The EA publish daily data on https://environment.data.gov.uk/\n",
    "# flood-monitoring/archive giving river levels about once every \n",
    "# couple of hours.  Each file is a huge dataset, so my first \n",
    "# task will be to extract the data from each of the stations \n",
    "# I am interested in, ditch the rest and put them together into \n",
    "# one dataframe lasting multiple days (possibly a month \n",
    "# eventually?)\n",
    "# I will aim to start with the last 5 days of February\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b9679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file has \"stationReference\" as the key field I can search \n",
    "# on to tie back to the data I have, without searching on a url.\n",
    "# From previously:\n",
    "#            ~ Cowley Bridge  = 45117\n",
    "#            ~ Upton Hellions = 45136\n",
    "#            ~ Yeoford        = 45137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e58e83bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#\n",
    "# Taking individual day files, and combining them into big whole\n",
    "# month df taking 3 sites of interest our of the bigdf saving \n",
    "# the whole month file back to my data folder with a new name\n",
    "#\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e81844cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2024-03-01', '2024-03-02', '2024-03-03', '2024-03-04',\n",
      "               '2024-03-05', '2024-03-06', '2024-03-07', '2024-03-08',\n",
      "               '2024-03-09', '2024-03-10', '2024-03-11', '2024-03-12',\n",
      "               '2024-03-13', '2024-03-14', '2024-03-15', '2024-03-16',\n",
      "               '2024-03-17', '2024-03-18', '2024-03-19', '2024-03-20',\n",
      "               '2024-03-21', '2024-03-22', '2024-03-23', '2024-03-24',\n",
      "               '2024-03-25', '2024-03-26', '2024-03-27', '2024-03-28',\n",
      "               '2024-03-29', '2024-03-30', '2024-03-31'],\n",
      "              dtype='datetime64[ns]', freq='D')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suzan\\AppData\\Local\\Temp\\ipykernel_13420\\3776385295.py:19: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mylist.append(pd.read_csv(f\"data/readings-full-{today.strftime(dayfmt)}.csv\"))\n",
      "C:\\Users\\suzan\\AppData\\Local\\Temp\\ipykernel_13420\\3776385295.py:19: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mylist.append(pd.read_csv(f\"data/readings-full-{today.strftime(dayfmt)}.csv\"))\n",
      "C:\\Users\\suzan\\AppData\\Local\\Temp\\ipykernel_13420\\3776385295.py:19: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mylist.append(pd.read_csv(f\"data/readings-full-{today.strftime(dayfmt)}.csv\"))\n",
      "C:\\Users\\suzan\\AppData\\Local\\Temp\\ipykernel_13420\\3776385295.py:19: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mylist.append(pd.read_csv(f\"data/readings-full-{today.strftime(dayfmt)}.csv\"))\n",
      "C:\\Users\\suzan\\AppData\\Local\\Temp\\ipykernel_13420\\3776385295.py:19: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mylist.append(pd.read_csv(f\"data/readings-full-{today.strftime(dayfmt)}.csv\"))\n",
      "C:\\Users\\suzan\\AppData\\Local\\Temp\\ipykernel_13420\\3776385295.py:19: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mylist.append(pd.read_csv(f\"data/readings-full-{today.strftime(dayfmt)}.csv\"))\n",
      "C:\\Users\\suzan\\AppData\\Local\\Temp\\ipykernel_13420\\3776385295.py:19: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mylist.append(pd.read_csv(f\"data/readings-full-{today.strftime(dayfmt)}.csv\"))\n",
      "C:\\Users\\suzan\\AppData\\Local\\Temp\\ipykernel_13420\\3776385295.py:19: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mylist.append(pd.read_csv(f\"data/readings-full-{today.strftime(dayfmt)}.csv\"))\n",
      "C:\\Users\\suzan\\AppData\\Local\\Temp\\ipykernel_13420\\3776385295.py:19: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mylist.append(pd.read_csv(f\"data/readings-full-{today.strftime(dayfmt)}.csv\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12324808 entries, 0 to 89291\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Dtype         \n",
      "---  ------            -----         \n",
      " 0   dateTime          datetime64[ns]\n",
      " 1   date              object        \n",
      " 2   measure           object        \n",
      " 3   station           object        \n",
      " 4   label             object        \n",
      " 5   stationReference  object        \n",
      " 6   parameter         object        \n",
      " 7   qualifier         object        \n",
      " 8   datumType         object        \n",
      " 9   period            int64         \n",
      " 10  unitName          object        \n",
      " 11  valueType         object        \n",
      " 12  value             object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(11)\n",
      "memory usage: 1.3+ GB\n"
     ]
    }
   ],
   "source": [
    "# Taking files and joining them into one df.  \n",
    "# Note I've been through this and manually changed the date range\n",
    "# I am interested in each time, rather than retype the code.\n",
    "# For only me this was just quicker than turning it into a \n",
    "# function on this occasion.\n",
    "                                                             \n",
    "startdate = \"2024-03-01\"     # start for subset of data\n",
    "enddate = \"2024-03-31\"       # end of the month I've downloaded\n",
    "startdt = pd.to_datetime(startdate, format='%Y-%m-%d')        \n",
    "enddt = pd.to_datetime(enddate, format='%Y-%m-%d')\n",
    "\n",
    "date_range = pd.date_range(start=startdt, end=enddt, freq='D')\n",
    "\n",
    "print(date_range)\n",
    "\n",
    "dayfmt = '%Y-%m-%d' \n",
    "mylist = []\n",
    "for today in date_range:\n",
    "    mylist.append(pd.read_csv(f\"data/readings-full-{today.strftime(dayfmt)}.csv\"))\n",
    "bigdf = pd.concat(mylist)\n",
    "\n",
    "bigdf[\"dateTime\"] = pd.to_datetime(bigdf[\"dateTime\"], \n",
    "                                   format='%Y-%m-%dT%H:%M:%SZ')\n",
    "bigdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee3b6c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6964 entries, 11383 to 66186\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   dateTime          6964 non-null   datetime64[ns]\n",
      " 1   date              6964 non-null   object        \n",
      " 2   measure           6964 non-null   object        \n",
      " 3   station           6964 non-null   object        \n",
      " 4   label             6964 non-null   object        \n",
      " 5   stationReference  6964 non-null   object        \n",
      " 6   parameter         6964 non-null   object        \n",
      " 7   qualifier         6964 non-null   object        \n",
      " 8   datumType         0 non-null      object        \n",
      " 9   period            6964 non-null   int64         \n",
      " 10  unitName          6964 non-null   object        \n",
      " 11  valueType         6964 non-null   object        \n",
      " 12  value             6964 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(11)\n",
      "memory usage: 761.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# so having extracted all data to one big dataframe, I want to \n",
    "# get out just the data for the sites I am interested in\n",
    "mask_for_cowley = bigdf[\"stationReference\"] == \"45117\"\n",
    "dfcowley = bigdf[mask_for_cowley]\n",
    "mask_for_upton = bigdf[\"stationReference\"] == \"45136\"\n",
    "dfupton = bigdf[mask_for_upton]\n",
    "mask_for_yeoford = bigdf[\"stationReference\"] == \"45137\"\n",
    "dfyeoford = bigdf[mask_for_yeoford]\n",
    "df = pd.concat([dfcowley, dfupton, dfyeoford], axis = 0)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdcaf49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputting data to new .csv file with just the data I want in\n",
    "# note I've manually changed the date in here each month to save \n",
    "# the new file.  I am aware that I could download concat dates \n",
    "# in one go, but for the sake of my laptop I've chosen to do it\n",
    "# a month at a time, knowing that my bigdf is pretty big!\n",
    "\n",
    "df.to_csv(\"data/df-2024-03.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11473d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateTime</th>\n",
       "      <th>date</th>\n",
       "      <th>measure</th>\n",
       "      <th>station</th>\n",
       "      <th>label</th>\n",
       "      <th>stationReference</th>\n",
       "      <th>parameter</th>\n",
       "      <th>qualifier</th>\n",
       "      <th>datumType</th>\n",
       "      <th>period</th>\n",
       "      <th>unitName</th>\n",
       "      <th>valueType</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11383</th>\n",
       "      <td>2024-03-01 00:45:00</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>http://environment.data.gov.uk/flood-monitorin...</td>\n",
       "      <td>http://environment.data.gov.uk/flood-monitorin...</td>\n",
       "      <td>Cowley Bridge</td>\n",
       "      <td>45117</td>\n",
       "      <td>level</td>\n",
       "      <td>Stage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900</td>\n",
       "      <td>m</td>\n",
       "      <td>instantaneous</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14330</th>\n",
       "      <td>2024-03-01 00:15:00</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>http://environment.data.gov.uk/flood-monitorin...</td>\n",
       "      <td>http://environment.data.gov.uk/flood-monitorin...</td>\n",
       "      <td>Cowley Bridge</td>\n",
       "      <td>45117</td>\n",
       "      <td>level</td>\n",
       "      <td>Stage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900</td>\n",
       "      <td>m</td>\n",
       "      <td>instantaneous</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14355</th>\n",
       "      <td>2024-03-01 00:30:00</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>http://environment.data.gov.uk/flood-monitorin...</td>\n",
       "      <td>http://environment.data.gov.uk/flood-monitorin...</td>\n",
       "      <td>Cowley Bridge</td>\n",
       "      <td>45117</td>\n",
       "      <td>level</td>\n",
       "      <td>Stage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900</td>\n",
       "      <td>m</td>\n",
       "      <td>instantaneous</td>\n",
       "      <td>0.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14380</th>\n",
       "      <td>2024-03-01 00:00:00</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>http://environment.data.gov.uk/flood-monitorin...</td>\n",
       "      <td>http://environment.data.gov.uk/flood-monitorin...</td>\n",
       "      <td>Cowley Bridge</td>\n",
       "      <td>45117</td>\n",
       "      <td>level</td>\n",
       "      <td>Stage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900</td>\n",
       "      <td>m</td>\n",
       "      <td>instantaneous</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26832</th>\n",
       "      <td>2024-03-01 01:45:00</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>http://environment.data.gov.uk/flood-monitorin...</td>\n",
       "      <td>http://environment.data.gov.uk/flood-monitorin...</td>\n",
       "      <td>Cowley Bridge</td>\n",
       "      <td>45117</td>\n",
       "      <td>level</td>\n",
       "      <td>Stage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900</td>\n",
       "      <td>m</td>\n",
       "      <td>instantaneous</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dateTime        date  \\\n",
       "11383 2024-03-01 00:45:00  2024-03-01   \n",
       "14330 2024-03-01 00:15:00  2024-03-01   \n",
       "14355 2024-03-01 00:30:00  2024-03-01   \n",
       "14380 2024-03-01 00:00:00  2024-03-01   \n",
       "26832 2024-03-01 01:45:00  2024-03-01   \n",
       "\n",
       "                                                 measure  \\\n",
       "11383  http://environment.data.gov.uk/flood-monitorin...   \n",
       "14330  http://environment.data.gov.uk/flood-monitorin...   \n",
       "14355  http://environment.data.gov.uk/flood-monitorin...   \n",
       "14380  http://environment.data.gov.uk/flood-monitorin...   \n",
       "26832  http://environment.data.gov.uk/flood-monitorin...   \n",
       "\n",
       "                                                 station          label  \\\n",
       "11383  http://environment.data.gov.uk/flood-monitorin...  Cowley Bridge   \n",
       "14330  http://environment.data.gov.uk/flood-monitorin...  Cowley Bridge   \n",
       "14355  http://environment.data.gov.uk/flood-monitorin...  Cowley Bridge   \n",
       "14380  http://environment.data.gov.uk/flood-monitorin...  Cowley Bridge   \n",
       "26832  http://environment.data.gov.uk/flood-monitorin...  Cowley Bridge   \n",
       "\n",
       "      stationReference parameter qualifier datumType  period unitName  \\\n",
       "11383            45117     level     Stage       NaN     900        m   \n",
       "14330            45117     level     Stage       NaN     900        m   \n",
       "14355            45117     level     Stage       NaN     900        m   \n",
       "14380            45117     level     Stage       NaN     900        m   \n",
       "26832            45117     level     Stage       NaN     900        m   \n",
       "\n",
       "           valueType  value  \n",
       "11383  instantaneous  0.808  \n",
       "14330  instantaneous  0.809  \n",
       "14355  instantaneous  0.806  \n",
       "14380  instantaneous  0.809  \n",
       "26832  instantaneous  0.803  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # simply confirming the data is as I want it to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa3122d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "721c4b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "#\n",
    "# Taking each month file and bolting them together into one \n",
    "# large file for longer duration saving multi month file back \n",
    "# with new file name \n",
    "#\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccd09554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having combined single day files into month files and then \n",
    "# extracted the sites I wanted, for each month, I need to then\n",
    "# combine these files into a year of data I am interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dba927dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2023-03-31', '2023-04-30', '2023-05-31', '2023-06-30',\n",
      "               '2023-07-31', '2023-08-31', '2023-09-30', '2023-10-31',\n",
      "               '2023-11-30', '2023-12-31', '2024-01-31', '2024-02-29'],\n",
      "              dtype='datetime64[ns]', freq='M')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 88314 entries, 0 to 4802\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   dateTime          88314 non-null  object \n",
      " 1   date              88314 non-null  object \n",
      " 2   measure           88314 non-null  object \n",
      " 3   station           88314 non-null  object \n",
      " 4   label             88314 non-null  object \n",
      " 5   stationReference  88314 non-null  int64  \n",
      " 6   parameter         88314 non-null  object \n",
      " 7   qualifier         88314 non-null  object \n",
      " 8   datumType         0 non-null      float64\n",
      " 9   period            88314 non-null  float64\n",
      " 10  unitName          88314 non-null  object \n",
      " 11  valueType         88314 non-null  object \n",
      " 12  value             88286 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(9)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Taking files of just my sites and joining them into one df.  \n",
    "                                                             \n",
    "startdate = \"2023-03\"        # start for subset of data            \n",
    "enddate = \"2024-03\"          # end of the month I've downloaded\n",
    "startdt = pd.to_datetime(startdate, format='%Y-%m')        \n",
    "enddt = pd.to_datetime(enddate, format='%Y-%m')\n",
    "\n",
    "date_range = pd.date_range(start=startdt, end=enddt, freq='M')\n",
    "\n",
    "print(date_range)\n",
    "\n",
    "dayfmt = '%Y-%m' \n",
    "mylist = []\n",
    "for month in date_range:\n",
    "    mylist.append(pd.read_csv(f\"data/df-{month.strftime(dayfmt)}.csv\"))\n",
    "df_all = pd.concat(mylist)\n",
    "\n",
    "\n",
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c7d2b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputting data to new .csv file with just the data I want in\n",
    "df_all.to_csv(\"data/df_all.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "500cd281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So df_all now contains 13 months of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedb2bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
